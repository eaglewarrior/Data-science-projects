{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "## Loading the data set\nfrom sklearn.datasets import fetch_20newsgroups\ntwenty_train = fetch_20newsgroups(subset='train', shuffle=True)",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(twenty_train.target_names) #prints all the categories\nprint(\"\\n\".join(twenty_train.data[0].split(\"\\n\")[:3])) #prints first line of the first data file",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\nFrom: lerxst@wam.umd.edu (where's my thing)\nSubject: WHAT car is this!?\nNntp-Posting-Host: rac3.wam.umd.edu\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "## Extracting features from text files\nfrom sklearn.feature_extraction.text import CountVectorizer\ncount_vect = CountVectorizer()\nX_train_counts = count_vect.fit_transform(twenty_train.data)\nX_train_counts.shape",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "(11314, 130107)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(twenty_train.data[1])",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "From: guykuo@carson.u.washington.edu (Guy Kuo)\nSubject: SI Clock Poll - Final Call\nSummary: Final call for SI clock reports\nKeywords: SI,acceleration,clock,upgrade\nArticle-I.D.: shelley.1qvfo9INNc3s\nOrganization: University of Washington\nLines: 11\nNNTP-Posting-Host: carson.u.washington.edu\n\nA fair number of brave souls who upgraded their SI clock oscillator have\nshared their experiences for this poll. Please send a brief message detailing\nyour experiences with the procedure. Top speed attained, CPU rated speed,\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\nfunctionality with 800 and 1.4 m floppies are especially requested.\n\nI will be summarizing in the next two days, so please add to the network\nknowledge base if you have done the clock upgrade and haven't answered this\npoll. Thanks.\n\nGuy Kuo <guykuo@u.washington.edu>\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "TF: Just counting the number of words in each document has 1 issue: it will give more weightage to longer documents than shorter documents. To avoid this, we can use frequency (TF - Term Frequencies) i.e. #count(word) / #Total words, in each document."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.feature_extraction.text import TfidfTransformer\ntfidf_transformer = TfidfTransformer()\nX_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\nX_train_tfidf.shape",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "(11314, 130107)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.naive_bayes import MultinomialNB\nclf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\n\n# Building a pipeline: We can write less code and do all of the above, by building a pipeline as follows:\n# The names ‘vect’ , ‘tfidf’ and ‘clf’ are arbitrary but will be used later.\n# We will be using the 'text_clf' going forward.\nfrom sklearn.pipeline import Pipeline\n\ntext_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n\ntext_clf = text_clf.fit(twenty_train.data, twenty_train.target)\n\n",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\n\n# Performance of NB Classifier\nimport numpy as np\ntwenty_test = fetch_20newsgroups(subset='test', shuffle=True)\npredicted = text_clf.predict(twenty_test.data)\nnp.mean(predicted == twenty_test.target)\n\n",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "0.7738980350504514"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Training Support Vector Machines - SVM and calculating its performance\n\nfrom sklearn.linear_model import SGDClassifier\ntext_clf_svm = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, n_iter=5, random_state=42))])\n\ntext_clf_svm = text_clf_svm.fit(twenty_train.data, twenty_train.target)\npredicted_svm = text_clf_svm.predict(twenty_test.data)\nnp.mean(predicted_svm == twenty_test.target)",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n  DeprecationWarning)\n",
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "0.8238183749336165"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Grid Search\n# Here, we are creating a list of parameters for which we would like to do performance tuning. \n# All the parameters name start with the classifier name (remember the arbitrary name we gave). \n# E.g. vect__ngram_range; here we are telling to use unigram and bigrams and choose the one which is optimal.\n\nfrom sklearn.model_selection import GridSearchCV\nparameters = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False), 'clf__alpha': (1e-2, 1e-3)}",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Next, we create an instance of the grid search by passing the classifier, parameters \n# and n_jobs=-1 which tells to use multiple cores from user machine.\n\ngs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\ngs_clf = gs_clf.fit(twenty_train.data, twenty_train.target)",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n  warnings.warn(CV_WARNING, FutureWarning)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# To see the best mean score and the params, run the following code\n\ngs_clf.best_score_\ngs_clf.best_params_\n\n# Output for above should be: The accuracy has now increased to ~90.6% for the NB classifier (not so naive anymore! )\n# and the corresponding parameters are {‘clf__alpha’: 0.01, ‘tfidf__use_idf’: True, ‘vect__ngram_range’: (1, 2)}.",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "{'clf__alpha': 0.01, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Similarly doing grid search for SVM\nfrom sklearn.model_selection import GridSearchCV\nparameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False),'clf-svm__alpha': (1e-2, 1e-3)}\n\ngs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, n_jobs=-1)\ngs_clf_svm = gs_clf_svm.fit(twenty_train.data, twenty_train.target)\n\n\ngs_clf_svm.best_score_\ngs_clf_svm.best_params_",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n  warnings.warn(CV_WARNING, FutureWarning)\n/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n  DeprecationWarning)\n",
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "{'clf-svm__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# NLTK\n# Removing stop words\nfrom sklearn.pipeline import Pipeline\ntext_clf = Pipeline([('vect', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()), \n                     ('clf', MultinomialNB())])",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Stemming Code\n\nimport nltk\n#nltk.download()\n\nfrom nltk.stem.snowball import SnowballStemmer\nstemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n\nclass StemmedCountVectorizer(CountVectorizer):\n    def build_analyzer(self):\n        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n    \nstemmed_count_vect = StemmedCountVectorizer(stop_words='english')\n\ntext_mnb_stemmed = Pipeline([('vect', stemmed_count_vect), ('tfidf', TfidfTransformer()), \n                             ('mnb', MultinomialNB(fit_prior=False))])\n\ntext_mnb_stemmed = text_mnb_stemmed.fit(twenty_train.data, twenty_train.target)\n\npredicted_mnb_stemmed = text_mnb_stemmed.predict(twenty_test.data)\n\nnp.mean(predicted_mnb_stemmed == twenty_test.target)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}